# de_summ2
This repository contains all code written for the Data Engineering course summative 2 assignment.
The code defines an Airflow DAG, ETL pipeline, and supporting functions to extract, transform, and load
data points from a FHIR EHR (Electronic Health Record) JSON files generated by the Synthea (https://synthea.mitre.org/)
tool.

## Requirements:
An install of Apache Airflow (https://airflow.apache.org/) and MySQL are required to run the pipeline. 

In the Airflow configuration settings, point the airflow dags_folder configuration variable to the
folder containing `ehr_pipeline.py` as this is the file which contains the DAG definition.

A running MySQL server instance containing a database named "ehr_db".

Configure a connector in Airflow with the name "mysql_ehr" to point to the MySQL server host. 

## Key files:
----------
pipeline.py  : contains the object classes and ETL pipeline functions
cfg.yaml     : contains locations of source and temporary output files
sql/ddl.sql  : SQL DDL statements used to create output tables in the schema
resources.py : contains helper functions and classes corresponding to each data-point type 
               currently Encounter, Condition, MedicationOrder, an Patient fields from the
               EHR are supported. New classes should be added to this file. 
